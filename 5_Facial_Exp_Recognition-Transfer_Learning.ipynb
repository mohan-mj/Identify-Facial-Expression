{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmo4cob\\AppData\\Local\\conda\\conda\\envs\\tf35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\jmo4cob\\AppData\\Local\\conda\\conda\\envs\\tf35\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "from keras.models import load_model\n",
    "import sys, tensorflow, keras\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 17:44:09) [MSC v.1900 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.8'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_arch=[(32,3),(64,3),(128,3)]\n",
    "dense=[64,2]\n",
    "dropout=0.5\n",
    "batch_size=128\n",
    "nb_epoch=100\n",
    "validation_split=0.2\n",
    "patience=5\n",
    "dirpath='model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(X_shape, y_shape, batch_size, dropout, nb_epoch, conv_arch, dense):\n",
    "    print (' X_train shape: ', X_shape) # (n_sample, 1, 48, 48)\n",
    "    print (' y_train shape: ', y_shape) # (n_sample, n_categories)\n",
    "    print ('      img size: ', X_shape[1], X_shape[2])\n",
    "    print ('    batch size: ', batch_size)\n",
    "    print ('      nb_epoch: ', nb_epoch)\n",
    "    print ('       dropout: ', dropout)\n",
    "#     print ('conv architect: ', conv_arch)\n",
    "#     print ('neural network: ', dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset:\n",
    "X_fname = 'dataset/X_train_data_Training.npy'\n",
    "y_fname = 'dataset/y_train_data_Training.npy'\n",
    "X_train = np.load(X_fname)\n",
    "y_train = np.load(y_fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = np.load('dataset/X_train_data_PublicTest.npy')\n",
    "y_val = np.load('dataset/y_train_data_PublicTest.npy')\n",
    "X_val = X_val.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " X_train shape:  (28709, 48, 48, 1)\n",
      " y_train shape:  (28709, 6)\n",
      "      img size:  48 48\n",
      "    batch size:  128\n",
      "      nb_epoch:  100\n",
      "       dropout:  0.5\n"
     ]
    }
   ],
   "source": [
    "starttime = time.time()\n",
    "X_train = X_train.astype('float32')\n",
    "X_shape = X_train.shape\n",
    "y_shape = y_train.shape\n",
    "describe(X_shape, y_shape, batch_size, dropout, nb_epoch, conv_arch, dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "InceptionV3_model = InceptionV3(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG16_model = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 48, 48, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'channels_last'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.image_data_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VGG16 Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "VGG16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG16_model_1 = Model(inputs=VGG16_model.get_input_at(0), outputs=VGG16_model.get_layer('block4_pool').output)\n",
    "VGG16_model_2 = Model(inputs=VGG16_model.get_input_at(0), outputs=VGG16_model.get_layer('block5_pool').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG16_model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = Input(shape=(139, 139, 3))\n",
    "InceptionV3_model = InceptionV3(input_tensor=input_tensor, input_shape=(139, 139, 3), weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = Input(shape=(48, 48, 3))\n",
    "VGG16_model = VGG16(input_tensor=input_tensor,  weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Sequential()\n",
    "# model.add(in_model)\n",
    "# model.add(BatchNormalization())\n",
    "base_model.add(Conv2D(3, kernel_size=1, strides=(1,1), input_shape=(48, 48, 1) , padding = 'same', \n",
    "                  activation = 'relu',data_format='channels_last'))\n",
    "#model.add(Conv2D(3, kernel_size = (1,1), padding = 'same', activation = 'relu'))\n",
    "#base_model.add(VGG16_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_189 (Conv2D)          (None, 48, 48, 3)         6         \n",
      "=================================================================\n",
      "Total params: 6\n",
      "Trainable params: 6\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add VGG16 Model to Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = VGG16_model(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(y_train.shape[1], activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers:\n",
    "    if layer.name == 'vgg16':\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conv2d_189_input --- False\n",
      "1 conv2d_189 --- False\n",
      "2 vgg16 --- False\n",
      "3 global_average_pooling2d_1 --- True\n",
      "4 dense_1 --- True\n",
      "5 dense_2 --- True\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name, '---' ,layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_189_input (InputLayer (None, 48, 48, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_189 (Conv2D)          (None, 48, 48, 3)         6         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                (None, 1, 1, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 6150      \n",
      "=================================================================\n",
      "Total params: 15,246,156\n",
      "Trainable params: 531,462\n",
      "Non-trainable params: 14,714,694\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/5\n",
      "28709/28709 [==============================] - 50s - loss: 11.2739 - val_loss: 10.4094\n",
      "Epoch 2/5\n",
      "28709/28709 [==============================] - 47s - loss: 6.4074 - val_loss: 1.7714\n",
      "Epoch 3/5\n",
      "28709/28709 [==============================] - 47s - loss: 1.5941 - val_loss: 1.6857\n",
      "Epoch 4/5\n",
      "28709/28709 [==============================] - 47s - loss: 1.4069 - val_loss: 1.6493\n",
      "Epoch 5/5\n",
      "28709/28709 [==============================] - 47s - loss: 1.2767 - val_loss: 1.6991s: 1.2 - ETA: 2s -\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24f8855bbe0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=y_train, batch_size=128, epochs=5, verbose=1, callbacks=None, \n",
    "    validation_split=0.0, validation_data=(X_val,y_val), shuffle=True, class_weight=None, \n",
    "    sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/Transfer_learning_model-1.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the Trainable Layers and Retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conv2d_189_input --- False\n",
      "1 conv2d_189 --- True\n",
      "2 vgg16 --- False\n",
      "3 global_average_pooling2d_1 --- True\n",
      "4 dense_1 --- True\n",
      "5 dense_2 --- True\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name,'---' ,layer.trainable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/5\n",
      "28709/28709 [==============================] - 96s - loss: 1.1720 - val_loss: 1.8359\n",
      "Epoch 2/5\n",
      "28709/28709 [==============================] - 94s - loss: 1.0357 - val_loss: 1.8773\n",
      "Epoch 3/5\n",
      "28709/28709 [==============================] - 93s - loss: 0.9279 - val_loss: 2.0047\n",
      "Epoch 4/5\n",
      "28709/28709 [==============================] - 94s - loss: 0.8298 - val_loss: 2.1234\n",
      "Epoch 5/5\n",
      "28709/28709 [==============================] - 94s - loss: 0.7425 - val_loss: 2.4052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24f8ba26630>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=y_train, batch_size=128, epochs=5, verbose=1, callbacks=None, \n",
    "    validation_split=0.0, validation_data=(X_val,y_val), shuffle=True, class_weight=None, \n",
    "    sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/Transfer_learning_model-2.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the Trainable Layers and Retrain - Train all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conv2d_189_input --- True\n",
      "1 conv2d_189 --- True\n",
      "2 vgg16 --- True\n",
      "3 global_average_pooling2d_1 --- True\n",
      "4 dense_1 --- True\n",
      "5 dense_2 --- True\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name,'---' ,layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/10\n",
      "28709/28709 [==============================] - 148s - loss: 0.8529 - val_loss: 1.9648\n",
      "Epoch 2/10\n",
      "28709/28709 [==============================] - 146s - loss: 0.6670 - val_loss: 2.0588\n",
      "Epoch 3/10\n",
      "28709/28709 [==============================] - 147s - loss: 0.5683 - val_loss: 2.1536\n",
      "Epoch 4/10\n",
      "28709/28709 [==============================] - 146s - loss: 0.4854 - val_loss: 2.1810\n",
      "Epoch 5/10\n",
      "28709/28709 [==============================] - 147s - loss: 0.4245 - val_loss: 2.2715\n",
      "Epoch 6/10\n",
      "28709/28709 [==============================] - 146s - loss: 0.3695 - val_loss: 2.3141\n",
      "Epoch 7/10\n",
      "28709/28709 [==============================] - 147s - loss: 0.3192 - val_loss: 2.4810\n",
      "Epoch 8/10\n",
      "28709/28709 [==============================] - 146s - loss: 0.2884 - val_loss: 2.5783\n",
      "Epoch 9/10\n",
      "28709/28709 [==============================] - 146s - loss: 0.2607 - val_loss: 2.7147\n",
      "Epoch 10/10\n",
      "28709/28709 [==============================] - 146s - loss: 0.2365 - val_loss: 2.8014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24f939d9ef0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=y_train, batch_size=128, epochs=10, verbose=1, callbacks=None, \n",
    "    validation_split=0.0, validation_data=(X_val,y_val), shuffle=True, class_weight=None, \n",
    "    sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/Transfer_learning_model-3.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
